{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Download Dependencies"
      ],
      "metadata": {
        "id": "3KmeqOp9CwaK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkT3njFRH59T",
        "outputId": "bc7057c9-33d4-4b75-c42a-62fd11f2da45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'facenet_pytorch'...\n",
            "remote: Enumerating objects: 1338, done.\u001b[K\n",
            "remote: Counting objects: 100% (293/293), done.\u001b[K\n",
            "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
            "remote: Total 1338 (delta 233), reused 225 (delta 217), pack-reused 1045 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1338/1338), 23.19 MiB | 42.32 MiB/s, done.\n",
            "Resolving deltas: 100% (662/662), done.\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cpu)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.0+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting mxnet\n",
            "  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (2.32.3)\n",
            "Collecting graphviz<0.9.0,>=0.8.1 (from mxnet)\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2024.8.30)\n",
            "Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.9.1\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.4.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.4.0+cpu)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.7-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (71.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Downloading torchmetrics-1.4.1-py3-none-any.whl (866 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.2/866.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.7-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.7 torchmetrics-1.4.1\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/timesler/facenet-pytorch.git facenet_pytorch\n",
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install mxnet\n",
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Packages"
      ],
      "metadata": {
        "id": "ll1b1se4DC6I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr70Q8UhKsjF",
        "outputId": "40b42341-02a6-4b0c-a967-05a4ecf68a24"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_xla/__init__.py:202: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n",
            "  warnings.warn(\n",
            "/content/facenet_pytorch/models/mtcnn.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(state_dict_path)\n",
            "/content/facenet_pytorch/models/mtcnn.py:79: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(state_dict_path)\n",
            "/content/facenet_pytorch/models/mtcnn.py:132: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(state_dict_path)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.bool = bool\n",
        "import mxnet as mx\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "from facenet_pytorch import MTCNN\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "from torchmetrics import Accuracy\n",
        "import torch_xla.utils.serialization as xser\n",
        "from Utils import preprocess_image, CANONICAL_LANDMARKS\n",
        "from CasiaWebFace import CASIAWebFaceDataset\n",
        "from Intermediate_Strategy import MobileFaceNetIntermediate\n",
        "from MobileFaceNet import MobileFaceNet\n",
        "from Later_Strategy import MobileFaceNetLater\n",
        "from LFW import LFWPairsDataset\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.datasets import fetch_lfw_pairs\n",
        "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cosine Similarity Function"
      ],
      "metadata": {
        "id": "CqYe1pKYDGfL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "930l8BVxGLah"
      },
      "outputs": [],
      "source": [
        "def eval_angles(model, threshold, device, dataloader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    angles = []  # This will store the cosine similarities\n",
        "    labels = []  # This will store the ground truth labels\n",
        "\n",
        "    for img1, img2, label in dataloader:\n",
        "        img1 = img1.to(device)  # Move first image to the appropriate device\n",
        "        img2 = img2.to(device)  # Move second image to the appropriate device\n",
        "\n",
        "        with torch.no_grad():  # Disable gradient calculation\n",
        "            # Get embeddings for both images\n",
        "            emb1 = model(img1)\n",
        "            emb2 = model(img2)\n",
        "\n",
        "            # Move tensors to CPU and convert to numpy arrays\n",
        "            emb1 = emb1.cpu().numpy().squeeze()  # Remove the extra dimension\n",
        "            emb2 = emb2.cpu().numpy().squeeze()  # Remove the extra dimension\n",
        "\n",
        "            # Calculate the cosine similarity between the embeddings\n",
        "            cosine_similarity_value = cosine_similarity([emb1], [emb2])[0][0]\n",
        "            cosine = np.clip(cosine_similarity_value, -1.0, 1.0)\n",
        "\n",
        "            # Store the cosine similarity and the label\n",
        "            angles.append(cosine)\n",
        "            labels.extend(label.cpu().numpy())  # Move labels to CPU and store\n",
        "\n",
        "    # Convert cosine similarities to binary predictions based on the threshold\n",
        "    predictions = [1 if cos_sim > threshold else 0 for cos_sim in angles]\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    accuracy = accuracy_score(labels, predictions) * 100\n",
        "    precision = precision_score(labels, predictions, zero_division=1) * 100\n",
        "    recall = recall_score(labels, predictions, zero_division=1) * 100\n",
        "    f1 = f1_score(labels, predictions, zero_division=1) * 100\n",
        "\n",
        "    # Return accuracy, precision, recall, and F1 score as a dictionary\n",
        "    metrics = {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1\n",
        "    }\n",
        "\n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize and Spawn Packages"
      ],
      "metadata": {
        "id": "d912Sb87DNIe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7d3Maz9nK9H",
        "outputId": "8457a52c-37d0-4dd5-873b-51be40d0b060"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-46-68082c443643>:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\"/content/xxx.pth\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 84.62%\n",
            "Precision: 84.62%\n",
            "Recall: 100.00%\n",
            "F1-Score: 91.67%\n"
          ]
        }
      ],
      "source": [
        "def _mp_fn(rank):\n",
        "    # Define the device as TPU\n",
        "    device = xm.xla_device()\n",
        "\n",
        "    # Define the mean and std for normalization\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "\n",
        "    def preprocess_and_transform(img):\n",
        "        img = transforms.ToTensor()(img)\n",
        "        img = transforms.Resize(112)(img)\n",
        "        img = transforms.Normalize(mean=mean, std=std)(img)\n",
        "        return img\n",
        "    # Define the transformation pipeline for validation and testing without augmentation\n",
        "    test_val_transform = transforms.Compose([\n",
        "        transforms.Lambda(preprocess_and_transform),\n",
        "    ])\n",
        "    lfw_pairs = fetch_lfw_pairs(color=True)\n",
        "    dataset = LFWPairsDataset(lfw_pairs, transform=test_val_transform)\n",
        "    dataset = [dataset[i] for i in range(1300)]\n",
        "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=8)\n",
        "\n",
        "    model = MobileFaceNetIntermediate(embedding_size=128).to(device)\n",
        "    checkpoint = torch.load(\"/content/xxx.pth\")\n",
        "    model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
        "\n",
        "    # Wrap DataLoader with MpDeviceLoader for TPU distributed loading\n",
        "    dataloader = pl.MpDeviceLoader(dataloader, device)\n",
        "\n",
        "    metrics = eval_angles(model, 0.5, device, dataloader)\n",
        "    xm.master_print(f\"Accuracy: {metrics['accuracy']:.2f}%\")\n",
        "    xm.master_print(f\"Precision: {metrics['precision']:.2f}%\")\n",
        "    xm.master_print(f\"Recall: {metrics['recall']:.2f}%\")\n",
        "    xm.master_print(f\"F1-Score: {metrics['f1_score']:.2f}%\")\n",
        "\n",
        "# Spawn the training across 8 TPU cores\n",
        "xmp.spawn(_mp_fn, args=(), nprocs=1, start_method='fork')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}